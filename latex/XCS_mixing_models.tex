\documentclass{ocsmnar}



% Adjust this to the language used.
\usepackage[ngerman]{babel}
\usepackage{hyperref}
\usepackage{amsmath}

\begin{document}


\title{Implementierung und Evaluation von Mixing-Modell-Alternativen für XCS}


\author{Markus Weis}

\maketitle




\section{Einleitung}
In modernen Michigan-Style Learning Classifier Systemen (LCS) wird üblicherweise aus einzelnen Classifier Vorhersagen eine Gesamtvorhersage berechnet. In XCS wird die Prediction über eine Fitness gewichtete Summe der einzelnen Predictions berechnet. Diese Fitness ist ein heuristisch Parameter, der inkrementell berechnet wird. Wilson schreibt, dass es wohl verschieden Möglichkeiten gibt, die Gesamtvorhersage zu berechnen, behält aber dieses Modell ohne weitere Ausführung in seinen späteren Arbeiten bei \cite{Wilson95}. 
Drugowitsch setzt in seinem Buch "Design and Analysis of Learning Classifier Systems - A Probabilistic Approach" \cite{book} dort an. Er beschreibt verschiedene Mixing Modelle und wertet diese empirisch aus. 
Einen dieser Modelle wird in der vorliegenden Arbeit beschrieben und eine Implementierung versucht: Inverse Variance Mixing. Aus den heuristisch Modellen schnitt dieses stets am besten ab, während die Laufzeit der  analytischen Lösung nicht angemessen ist. Das Modell wird im Open-Source Projekt scikit-XCS \cite{repo}, einer scikit-learn Erweiterung für XCS, implementiert. 

\section{Inverse Variance Mixing}
Die Definition des Inverse Variance Mixing ist \cite{book} entnommen. 

$$ \tau_{k}^{-1} = (c_{k} - D^{X}) \sum_{n}^{N} m_{k}(x_{n}) (\hat{w}_{k}^T x_{n} - y_{n})^{2}$$

Dabei ist $\tau_{k}^{-1}$ die Varianz und folglich $\tau_{k}$ die inverse Invarianz. $C_{k}$ ist der Matchcount des Classifiers k, $D^{X}$ ist die Dimension des Input Raums. $m_{k}(x)$ ist eine Matching-Funktion für die gilt: $m_{k}(x) = 1$, falls die Bedingung des Classifiers k auf x passt und $m_{k}(x) = 0$ sonst. 
Der hintere Term stellt das quadratische Fehlermaß der Regression dar. Dieser muss hier angepasst  werden, da Klassifikation implementiert werden soll.

Die erste Implementation lautet wie folgt: 

$$ \tau_{k}^{-1} = (c_{k} - D^{X}) \sum_{n}^{N} m_{k}(x_{n})f_{k}(x_{n}) $$

Wobei $f_{k}(x)$ den Klassifikationsfehler darstellen soll: $f_{k}(x) = 0$, falls Classifier k die richtige Klasse für Input x hat und $f_{k}(x) = 1$, sonst. 

Später wurde statt der Klasse noch der Fehler der Prediction als Fehlermaß verwendet:

$$ \tau_{k}^{-1} = (c_{k} - D^{X}) \sum_{n}^{N} m_{k}(x_{n}) |p_{k} - P_{k}(x)|  $$

$p_{k}$ ist die Prediction des Classifiers k, $P_{k}(x)$ ist der Reward der ausgeschüttet wird wenn Classifier k auf Input x seine Klasse vorhersagt. 
Statt dem Betrag wurde auch versucht den Fehler zu quadrieren, dies hatte aber keine relevanten Auswirkungen.

Schließlich wird die inverse Varianz nicht direkt benutzt, sondern noch der sog. Gating Parameter $g_{k}$ über das aktuelle Matchset berechnet: 
$$ g_k(x) = \frac{m_k(x)\tau_k}{m_i(x)\sum_i^K \tau_i}$$

Dadurch wird sichergestellt, dass die Summe aller Gating Parameter für jeden Input 1 ergibt. 




\section{Probleme}
Im Buch wurde Inverse Variance Mixing nie im XCS-Context benutzt. Stattdessen wurde sie im allgemeineren Context von LCS definiert. LCS Classifier im Buch wurden durch Batch Learning trainiert werden und nicht iterativ, wie es bei XCS der Fall ist. 
Ein erster Ansatz der Implementierung hier war einfach die Fitness der einzelnen Classifier durch die inverse Variance zu ersetzten. 
Daraus ergaben sich aber 2 Probleme: 

1. Da man für alle Classifier, die für die aktuelle Prediction verantwortlich sind, die Fitness updatet, müsste man für alle diese die inverse variance neu berechnen. Dazu wird aber für jeden Classifier das komplette Trainingsset durchlaufen. Dies führt zu einer nicht akzeptablen Laufzeit. Hier müsste wie im restlichen XCS ein iterativer Ansatz verfolgt werden. Dies wurde hier nicht gemacht, da man sich dadurch noch weiter von der ursprünglichen Idee entfernt und weiter Hyperparameter eingefügt werden müssten. 
Stattdessen wurde hier die Laufzeit erstmal in Kauf genommen und geschaut, ob so gute Ergebnisse auftreten.  

2. Das Erzeugen neuer Classifier benutzt die Fitness als Auswahlkriterium. Allerdings ist die Inverse Variance zu Beginn des Training Vorgangs noch nicht als sinnvoll zu betrachten. Beispielsweise wird ein Classifier, der auf einen Input perfekt passt stets bevorzugt, egal ob es allgemeinere gibt, die ähnlich gut sind. 

Wir sind schließlich zu dem Schluss gekommen, die Fitness des ursprünglichen XCS Systems in Ruhe zu lassen und die Inverse Variance nur für das Mixing zu benutzten. Das Problem mit der Laufzeit besteht aber, da für die Prediction bei nicht Explorationsiterationen berechnet werden muss. Schließlich wurden 2 Alternativen implementiert. Die eine macht die Prediction während des Trainings bereits mit der inversen Invarianz und zeigt deshalb eine sehr schlecht Laufzeit auf. Bei der anderen wird die neue Mixing Art nur bei Predictions benutzt, die nicht während des Trainings auftreten, also nur im Fertigen Model. Das hat den Vorteil, das die inverse Varianz für alle Classifier am Ende des Trainingsprozesses berechnet werden kann und für die einzelnen Prediction nur der Gating Parameter aktualisiert werden muss.  
 


Wie bereits beschrieben handelt es sich bei der eigentlichen Definition um Regression. Bei Regression ist es unwahrscheinlich bzw. unmöglich, je nach Modell, auf einen perfekten Classifier zu treffen. Das Problem bei einem perfekten Classifier ist, dass der hintere Teil der Formel 0 ergibt. Das wird zum Problem, wenn man zur Berechnung der Inversen Varianz den Umkehrbruch bildet. Im Buch ist das nicht weiter definiert. In dieser Implementation habe ich in diesem Fall Unendlich (numpy.inf) eingesetzt. Dadurch bekommt man schließlich im Mixing Probleme. Zwar bekommt man bei einem Unendlich beim Mixing-Parameter $g_{k}$ bei allen anderen Classifiern, die nicht Unendlich sind 0 raus, allerdings ist $f\frac{numpy.inf}{numpy.inf}$ nicht definiert. Stattdessen wird $g_{k}$ im Falle eines Classifiers k im Matchset mit $\gamma_{k} = \infty$ wie folgt berechnet: $g_{k} = \frac{1}{c_{inf}} $ für alle Classifier k mit $\gamma_{k} = \infty$ und $g_{k} = 0$ für alle anderen Classifier. $c_{inf}$ ist die Anzahl der Classifier mit $\gamma_{k} = \infty$.

Ein weiteres Problem ergab sich im Fall, dass der Matchcount $c_k$ für einige Classifier geringer als die Dimension des Inputs war, sodass sich für die Varianz und die negative Varianz ein negativer Wert ergibt. Im Buch ist nicht beschrieben, wie in diesem Fall mit den Classifiern umgegangen werden soll. %TODO: Was mach ich denn damit?










\section{Ergebnisse}
Die Implementierung wurde auf Multiplexern verschiedener Größe evaluiert: 6 Bit, 11 Bit und 20 Bit. Die Trainingsdauer und die Hyperparameter orientieren sich an \cite{iqbal13}. Dort ist zu entnehmen, wie viele Iterationen XCS braucht, um die verschieden großen Multiplexer perfekt zu lernen. Letztendlich wäre jedes der hier zu evaluierenden Implementierungen bei den Problemen zu einer perfekte Accuracy gekommen, wenn man nur lange genug trainiert. Es wäre wohl sinnvoll die Implementierungen auch auf Problemen zu testen, bei denen XCS keine perfekte Lösung finden kann. Dies wird hier allerdings nicht gemacht. 
Es wird für 4000, 10000, 40000 Iterationen für den 6-Bit, 11-Bit und 20-Bit Multiplexer trainiert. 
Die durchschnittliche Accuracy der Cross-Validation ist der Tabelle %TODO:
 zu entnehmen. Dabei wurde beim 6-Bit Multiplexer eine 10x5, beim 11-Bit Multiplexer eine 5x5 und beim 20-Bit Multiplexer eine 2x5 Cross-Validation durchgeführt. Dies liegt an der langen Laufzeit der Implementierung mit dem kontinuierlichen Update der inversen Variance. 

\begin{center}
\begin{tabular}{|c|c|c|c|}
    \hline
    & 6 Bit & 11 Bit & 20 Bit \\
    \hline
    normal & & & \\
    \hline
    evenly-distributed & & &\\
    \hline
    only-mixing & & & \\
    \hline
    continuous-update & & & \\
    \hline
\end{tabular}
\end{center}

\section{Fazit}
Die hier beschrieben Ergebnisse zeigen, dass das Inverse Variance Mixing, wie es hier implementiert ist, sicher nicht als sinnvolle Alternative zum gewöhnlichen XCS-Mixing benutzt werden kann. In dieser Implementierung wurde allerdings notwendigerweise stark von der eigentlichen vorgeschlagenen Heuristik abgewichen. Welche der Abweichungen zu den schlechten Resultaten führt ist schwer zu sagen. 
Es handelte sich hierbei eher um einen praktischen Versuch und die formale Korrektheit wurde dabei vernachlässigt. Dies war aufgrund der Komplexität des Themas und der beschränkten Zeit notwendig. Es kann also sein, dass es durchaus sinnvolle Implementierung von Inverse Variance Mixing in XCS gibt, v.a. da hier nur Klassifikation betrachtet wurde. 
Auffällig ist, dass das Mixing mit gleicher Verteilung der Classifier relativ gut abschneidet und bei hier vorliegenden Versuchsaufbau keine statische Signifikanz zum normalen XCS-Mixing vorliegt. Dies deutet darauf hin, dass das XCS Mixing nicht optimal ist. Weiter Mixing Modelle sollten daher ausprobiert werden.  













\bibliographystyle{ACM-Reference-Format}
\bibliography{References}


\end{document}
